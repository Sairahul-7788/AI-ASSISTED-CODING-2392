{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+/EeyAlb9Jm7B5cOQ67Kh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sairahul-7788/AI-ASSISTED-CODING-2392/blob/main/AI_LAB_5_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhRiU4rIyu5L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07aeb6ab",
        "outputId": "47036143-475d-46d3-ebf6-fa02129615b3"
      },
      "source": [
        "# 1. Collect user data\n",
        "name = input(\"Enter your name: \")\n",
        "\n",
        "while True:\n",
        "    age_input = input(\"Enter your age: \")\n",
        "    # 2. Validate age (should be a number)\n",
        "    if age_input.isdigit():\n",
        "        age = int(age_input)\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid age. Please enter a number.\")\n",
        "\n",
        "while True:\n",
        "    email = input(\"Enter your email: \")\n",
        "    # 2. Validate email (should contain '@')\n",
        "    if '@' in email:\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid email. Please include '@' in your email address.\")\n",
        "\n",
        "# 3. Print the collected data\n",
        "print(\"\\n--- Collected Data ---\")\n",
        "print(f\"Name: {name}\")\n",
        "print(f\"Age: {age}\")\n",
        "print(f\"Email: {email}\")\n",
        "\n",
        "# --- Data Anonymization and Protection Comments ---\n",
        "# These comments explain methods to protect user data. No encryption libraries are implemented here.\n",
        "\n",
        "# 1. Masking or Hashing Personal Data:\n",
        "#    - Masking: Replace sensitive parts of data with generic characters (e.g., email: 'user***@example.com').\n",
        "#      Example: masked_email = email.split('@')[0][:3] + '***@' + email.split('@')[1]\n",
        "#    - Hashing: Transform data into a fixed-size string of characters using a one-way function (e.g., SHA256).\n",
        "#      This makes it impossible to reverse engineer the original data from the hash, but allows for checking integrity.\n",
        "#      Example (conceptual, requires 'hashlib' library):\n",
        "#      import hashlib\n",
        "#      hashed_email = hashlib.sha256(email.encode()).hexdigest()\n",
        "#      hashed_name = hashlib.sha256(name.encode()).hexdigest()\n",
        "\n",
        "# 2. Avoiding Plaintext Storage:\n",
        "#    - Never store sensitive user data (like passwords, full emails, or names) directly in plain text in databases or files.\n",
        "#    - Always use secure methods like hashing for passwords and encryption for other PII (Personally Identifiable Information).\n",
        "\n",
        "# 3. Using Encryption (concept19\n",
        "ual, not implemented):\n",
        "#    - Encryption involves converting data into a coded format to prevent unauthorized access.\n",
        "#    - Symmetric encryption uses the same key for encryption and decryption.\n",
        "#    - Asymmetric encryption uses a pair of keys (public and private) for encryption and decryption.\n",
        "#    - Libraries like 'cryptography' in Python can be used for robust encryption.\n",
        "#    - Example (conceptual):\n",
        "#      encrypted_data = encrypt_function(sensitive_data, encryption_key)\n",
        "#      decrypted_data = decrypt_function(encrypted_data, decryption_key)\n",
        "\n",
        "# 4. Following Privacy Best Practices:\n",
        "#    - Minimal Data Collection: Only collect the data absolutely necessary for your service.\n",
        "#      For example, if you don't need a user's full address, don't ask for it.\n",
        "#    - Data Retention Policies: Define how long user data will be stored and delete it when no longer needed.\n",
        "#    - Access Control: Restrict who can access sensitive user data within your organization.\n",
        "#    - Consent: Always obtain clear and explicit consent from users before collecting and processing their data.\n",
        "#    - Regular Audits: Periodically review your data handling practices to ensure compliance with privacy regulations (e.g., GDPR, CCPA)."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your name: rahul\n",
            "Enter your age: 19\n",
            "Enter your email: rahul@gmail.com\n",
            "\n",
            "--- Collected Data ---\n",
            "Name: rahul\n",
            "Age: 19\n",
            "Email: rahul@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5f0408",
        "outputId": "7c209a70-1f4d-4ac2-ba02-90fb88b62ab6"
      },
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def analyze_sentiment(texts):\n",
        "    \"\"\"\n",
        "    Performs basic sentiment analysis on a list of text inputs.\n",
        "    Classifies each text as 'Positive', 'Negative', or 'Neutral'.\n",
        "\n",
        "    Args:\n",
        "        texts (list): A list of strings, where each string is a text input.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing the original text\n",
        "              and its predicted sentiment.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for text in texts:\n",
        "        analysis = TextBlob(text)\n",
        "        sentiment = ''\n",
        "        if analysis.sentiment.polarity > 0: # Polarity > 0 indicates positive sentiment\n",
        "            sentiment = 'Positive'\n",
        "        elif analysis.sentiment.polarity < 0: # Polarity < 0 indicates negative sentiment\n",
        "            sentiment = 'Negative'\n",
        "        else: # Polarity = 0 indicates neutral sentiment\n",
        "            sentiment = 'Neutral'\n",
        "        results.append({\"text\": text, \"sentiment\": sentiment, \"polarity\": analysis.sentiment.polarity})\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "texts_to_analyze = [\n",
        "    \"I love this product, it's amazing!\",\n",
        "    \"This is a terrible experience.\",\n",
        "    \"The weather is okay today.\",\n",
        "    \"I am so happy and excited about the new features.\",\n",
        "    \"I am not satisfied at all.\",\n",
        "    \"That's just great!\", # Sarcasm example\n",
        "    \"The movie was good but the ending was disappointing.\"\n",
        "]\n",
        "\n",
        "sentiment_results = analyze_sentiment(texts_to_analyze)\n",
        "for res in sentiment_results:\n",
        "    print(f\"Text: '{res['text']}' | Sentiment: {res['sentiment']} (Polarity: {res['polarity']:.2f})\")\n",
        "\n",
        "\n",
        "# --- Comments on Biases in Sentiment Analysis Data ---\n",
        "\n",
        "# Sentiment analysis models, especially simple rule-based or library-based ones,\n",
        "# are prone to various biases inherent in the data they are trained on or the rules they follow.\n",
        "\n",
        "# 1. Language and Cultural Bias:\n",
        "#    - Explanation: Sentiment can be expressed differently across languages and cultures.\n",
        "#      A word or phrase considered positive in one language/culture might be neutral or even negative in another.\n",
        "#      Also, regional dialects, slang, and cultural nuances can significantly impact interpretation.\n",
        "#    - Identification: Test the model with texts from diverse linguistic and cultural backgrounds.\n",
        "#      Look for inconsistent performance across different demographic groups.\n",
        "#    - Mitigation: Use diverse, multicultural datasets for training. Implement language-specific models or adapt rules.\n",
        "#      Involve native speakers/cultural experts in dataset annotation and model evaluation.\n",
        "\n",
        "# 2. Sarcasm and Context Misinterpretation:\n",
        "#    - Explanation: Humans struggle with sarcasm, and sentiment analysis models often fail to detect it.\n",
        "#      Phrases like \"Oh, that's just great!\" can be highly positive literally but sarcastically negative.\n",
        "#      Models also often struggle with negations (e.g., \"not bad\" vs. \"bad\") and subtle contextual cues.\n",
        "#    - Identification: Manually review model predictions for sarcastic or context-dependent phrases.\n",
        "#      Create specific test sets designed to include sarcastic statements and complex negations.\n",
        "#    - Mitigation: Incorporate contextual understanding (e.g., entity recognition, dependency parsing) if possible.\n",
        "#      More advanced models often use transformers for better contextual understanding.\n",
        "#      Human review and post-processing can help flag and correct such instances.\n",
        "\n",
        "# 3. Imbalanced Datasets:\n",
        "#    - Explanation: If the training data heavily favors one sentiment class (e.g., mostly positive reviews),\n",
        "#      the model may become biased towards predicting that class, even when it's not appropriate.\n",
        "#      This can lead to poor performance on underrepresented classes.\n",
        "#    - Identification: Examine the distribution of sentiment labels in the dataset. If one class is dominant,\n",
        "#      it's an imbalanced dataset. Check precision, recall, and F1-score for each class, not just overall accuracy.\n",
        "#    - Mitigation: Use sampling techniques (oversampling minority class, undersampling majority class).\n",
        "#      Employ appropriate evaluation metrics for imbalanced datasets (e.g., F1-score, Matthews correlation coefficient).\n",
        "#      Collect more diverse data to balance the classes.\n",
        "\n",
        "# 4. Subjective Labeling:\n",
        "#    - Explanation: What one person considers 'neutral' or 'slightly positive' might be 'negative' to another.\n",
        "#      Sentiment can be subjective, especially for nuanced opinions or factual statements with an underlying tone.\n",
        "#      Disagreements among human annotators lead to noisy labels that can bias the model.\n",
        "#    - Identification: Calculate inter-annotator agreement (e.g., Cohen's Kappa) if multiple humans label the same data.\n",
        "#      Analyze examples where human annotators disagree significantly.\n",
        "#    - Mitigation: Establish clear and consistent annotation guidelines. Use multiple annotators and resolve disagreements\n",
        "#      through consensus or aggregation. Focus on clear-cut cases for initial training and use human-in-the-loop\n",
        "#      systems for ambiguous cases.\n",
        "\n",
        "# --- General Mitigation Strategies for Biases ---\n",
        "# - Diverse Data Collection: Ensure datasets represent a wide range of demographics, topics, writing styles, and sentiments.\n",
        "# - Bias Evaluation Metrics: Beyond accuracy, use metrics that assess fairness and performance across different groups.\n",
        "# - Explainable AI (XAI): Use techniques to understand why a model makes certain predictions, which can reveal biases.\n",
        "# - Regular Audits and Monitoring: Continuously test and monitor the model's performance in real-world scenarios.\n",
        "# - Human Review/Human-in-the-Loop: Integrate human oversight to correct errors, especially for critical decisions.\n",
        "# - Ethical Guidelines: Develop and adhere to ethical guidelines for data collection, model development, and deployment.\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'I love this product, it's amazing!' | Sentiment: Positive (Polarity: 0.62)\n",
            "Text: 'This is a terrible experience.' | Sentiment: Negative (Polarity: -1.00)\n",
            "Text: 'The weather is okay today.' | Sentiment: Positive (Polarity: 0.50)\n",
            "Text: 'I am so happy and excited about the new features.' | Sentiment: Positive (Polarity: 0.44)\n",
            "Text: 'I am not satisfied at all.' | Sentiment: Negative (Polarity: -0.25)\n",
            "Text: 'That's just great!' | Sentiment: Positive (Polarity: 1.00)\n",
            "Text: 'The movie was good but the ending was disappointing.' | Sentiment: Positive (Polarity: 0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P05zKocD2Gkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af192e3d",
        "outputId": "42c60847-e2c1-4d67-884e-f147b0601ecc"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def recommend_products(user_history, num_recommendations=5):\n",
        "    \"\"\"\n",
        "    Recommends products based on a user's past purchase or browsing history\n",
        "    using a simple frequency-based approach.\n",
        "\n",
        "    Args:\n",
        "        user_history (list): A list of strings, where each string represents\n",
        "                             a product that the user has interacted with.\n",
        "        num_recommendations (int): The maximum number of recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of recommended product names.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Count the frequency of each product in the user's history\n",
        "    #    This helps identify products the user interacts with most often.\n",
        "    product_counts = Counter(user_history)\n",
        "\n",
        "    # 2. Get the most common products from the user's history\n",
        "    #    These are often good candidates for recommendation as they reflect preference.\n",
        "    most_common_products = [product for product, count in product_counts.most_common()]\n",
        "\n",
        "    # 3. Define a set of general popular items (as a simple fallback/diversification strategy)\n",
        "    #    In a real system, this would come from overall site analytics.\n",
        "    popular_products = [\n",
        "        \"Laptop\", \"Smartphone\", \"Headphones\", \"Smartwatch\", \"Gaming Console\",\n",
        "        \"Webcam\", \"External Hard Drive\", \"Monitor\", \"Keyboard\", \"Mouse\"\n",
        "    ]\n",
        "\n",
        "    recommendations = []\n",
        "    # First, add the most common products from the user's history\n",
        "    for product in most_common_products:\n",
        "        if product not in recommendations: # Avoid duplicating if already added\n",
        "            recommendations.append(product)\n",
        "            if len(recommendations) >= num_recommendations:\n",
        "                return recommendations[:num_recommendations]\n",
        "\n",
        "    # Then, add popular products that are not in the user's history or already recommended\n",
        "    for product in popular_products:\n",
        "        if product not in user_history and product not in recommendations:\n",
        "            recommendations.append(product)\n",
        "            if len(recommendations) >= num_recommendations:\n",
        "                break\n",
        "\n",
        "    return recommendations[:num_recommendations]\n",
        "\n",
        "# --- Example Usage ---\n",
        "print(\"--- Product Recommendation System ---\")\n",
        "\n",
        "# Simulate a user's past history\n",
        "user_1_history = [\n",
        "    \"Laptop\", \"Headphones\", \"Laptop\", \"Monitor\", \"Mouse\",\n",
        "    \"Keyboard\", \"Laptop\", \"Webcam\", \"Headphones\", \"Monitor\",\n",
        "    \"Mouse\", \"Gaming Console\", \"Laptop\"\n",
        "]\n",
        "\n",
        "user_2_history = [\n",
        "    \"Smartphone\", \"Smartwatch\", \"Smartphone\", \"Headphones\", \"Bluetooth Speaker\"\n",
        "]\n",
        "\n",
        "# Get recommendations for User 1\n",
        "print(\"\\nUser 1 History:\", user_1_history)\n",
        "user_1_recommendations = recommend_products(user_1_history)\n",
        "print(\"User 1 Recommended Products:\", user_1_recommendations)\n",
        "\n",
        "# Get recommendations for User 2\n",
        "print(\"\\nUser 2 History:\", user_2_history)\n",
        "user_2_recommendations = recommend_products(user_2_history)\n",
        "print(\"User 2 Recommended Products:\", user_2_recommendations)\n",
        "\n",
        "# --- Ethical Guidelines for Recommendation Systems (Comments) ---\n",
        "\n",
        "# 1. Transparency:\n",
        "#    - Explanation: Users should understand why certain products are recommended to them.\n",
        "#      This code uses a frequency-based approach: it recommends items the user has interacted with most\n",
        "#      frequently, along with generally popular items they haven't seen. This logic is simple and clear.\n",
        "#      In more complex systems, explaining \"people who bought X also bought Y\" or \"because you viewed Z\" enhances trust.\n",
        "\n",
        "# 2. Fairness:\n",
        "#    - Explanation: Recommendation systems should not unfairly prioritize certain products or brands\n",
        "#      (e.g., those with higher margins or from a parent company) without clear justification.\n",
        "#      This simple system tries to be fair by prioritizing user's explicit past interests.\n",
        "#      However, simply recommending only the most frequent items could create a \"filter bubble\" or reduce serendipity.\n",
        "#      Mitigation: Incorporate diversity metrics. Ensure a variety of brands/categories are suggested over time.\n",
        "#      Regularly audit recommendations to ensure they don't disproportionately favor or disadvantage certain groups of products or users.\n",
        "\n",
        "# 3. Bias Awareness:\n",
        "#    - Explanation: Recommendation data often reflects historical biases present in user behavior.\n",
        "#      If a user's history is limited, or if certain demographics are underrepresented in the data,\n",
        "#      the recommendations can become biased (e.g., only recommending tech gadgets to a user whose history only shows tech).\n",
        "#      This simple model is biased towards past behavior and overall popular items.\n",
        "#      Mitigation: Use diverse datasets that represent various user preferences and demographics.\n",
        "#      Monitor recommendation outcomes for different user segments to detect and correct unfair biases.\n",
        "#      Introduce serendipity (novel or unexpected recommendations) to break out of established patterns.\n",
        "\n",
        "# 4. User Control:\n",
        "#    - Explanation: Users should have control over their recommendation experience.\n",
        "#      They should be able to provide feedback, modify their preferences, or opt out of recommendations.\n",
        "#      Example features (conceptual, not implemented here):\n",
        "#      - \"Not interested in this product\" button to remove an item from recommendations.\n",
        "#      - \"Why am I seeing this?\" button to explain the recommendation logic.\n",
        "#      - Ability to explicitly add or remove product categories from their preferences.\n",
        "#      - Option to clear or modify their purchase/browsing history that feeds the recommendations.\n",
        "#      - Toggle to turn off personalized recommendations entirely, defaulting to general popular items.\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Product Recommendation System ---\n",
            "\n",
            "User 1 History: ['Laptop', 'Headphones', 'Laptop', 'Monitor', 'Mouse', 'Keyboard', 'Laptop', 'Webcam', 'Headphones', 'Monitor', 'Mouse', 'Gaming Console', 'Laptop']\n",
            "User 1 Recommended Products: ['Laptop', 'Headphones', 'Monitor', 'Mouse', 'Keyboard']\n",
            "\n",
            "User 2 History: ['Smartphone', 'Smartwatch', 'Smartphone', 'Headphones', 'Bluetooth Speaker']\n",
            "User 2 Recommended Products: ['Smartphone', 'Smartwatch', 'Headphones', 'Bluetooth Speaker', 'Laptop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dUBHI9xD3EcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43b36210",
        "outputId": "f49423dd-984b-4159-c4da-b6720884add8"
      },
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "# --- 1. Logging Configuration ---\n",
        "\n",
        "# Create a logger\n",
        "# The root logger is generally not configured directly. It's better to get a named logger.\n",
        "# For a simple app, we can configure the root logger or a specific app logger.\n",
        "app_logger = logging.getLogger('web_app')\n",
        "app_logger.setLevel(logging.INFO) # Set the minimum logging level to INFO\n",
        "\n",
        "# Create handlers\n",
        "# StreamHandler for console output\n",
        "console_handler = logging.StreamHandler(sys.stdout)\n",
        "console_handler.setLevel(logging.INFO) # Console will show INFO and above\n",
        "\n",
        "# FileHandler for logging to a file\n",
        "# In a real application, you'd want to manage log file rotation, size, etc.\n",
        "file_handler = logging.FileHandler('app.log')\n",
        "file_handler.setLevel(logging.WARNING) # File will only store WARNING and above\n",
        "\n",
        "# Create a formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "console_handler.setFormatter(formatter)\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "# Add the handlers to the logger\n",
        "app_logger.addHandler(console_handler)\n",
        "app_logger.addHandler(file_handler)\n",
        "\n",
        "# --- 2. Simulate a minimal Flask-style web application ---\n",
        "\n",
        "def handle_request(request_data):\n",
        "    app_logger.info(f\"Request received for path: {request_data.get('path')}\")\n",
        "\n",
        "    # --- Privacy & Security: Sensitive Data Handling ---\n",
        "    # NEVER log sensitive information directly. This includes passwords, API tokens,\n",
        "    # personal identifiable information (PII) like full names, addresses, emails,\n",
        "    # phone numbers, financial details, or any other data that could compromise user privacy or security.\n",
        "    # Logging sensitive data can lead to serious data breaches, regulatory fines (e.g., GDPR, CCPA),\n",
        "    # and erosion of user trust.\n",
        "\n",
        "    user_password = request_data.get('password')\n",
        "    user_email = request_data.get('email')\n",
        "    api_token = request_data.get('api_token')\n",
        "    payment_card_number = request_data.get('card_number')\n",
        "\n",
        "    # --- UNSAFE LOGGING EXAMPLE (DO NOT USE IN PRODUCTION) ---\n",
        "    # This is commented out to prevent accidental logging of sensitive data.\n",
        "    # app_logger.info(f\"User {user_email} attempted login with password {user_password}\") # EXPOSES PASSWORD\n",
        "    # app_logger.warning(f\"API call with token: {api_token}\") # EXPOSES API TOKEN\n",
        "\n",
        "    # --- SAFE LOGGING EXAMPLE: Masking/Excluding Sensitive Data ---\n",
        "    if user_email:\n",
        "        # Mask email: show only a part of it, or hash it before logging if needed for tracking.\n",
        "        # For simple logging, often just noting an action occurred is enough.\n",
        "        masked_email = f\"{user_email.split('@')[0][:2]}***@{user_email.split('@')[1]}\"\n",
        "        app_logger.info(f\"Login attempt detected for user: {masked_email}\")\n",
        "    else:\n",
        "        app_logger.info(\"Login attempt detected (email not provided).\")\n",
        "\n",
        "    if 'error_code' in request_data:\n",
        "        error_message = request_data.get('error_message', 'An unknown error occurred')\n",
        "        app_logger.error(f\"Application error: {request_data['error_code']} - {error_message}\")\n",
        "        app_logger.warning(\"Investigate application error immediately.\")\n",
        "\n",
        "    app_logger.info(\"Request processing complete.\")\n",
        "\n",
        "\n",
        "# --- Example Usage (Simulating requests) ---\n",
        "if __name__ == \"__main__\":\n",
        "    app_logger.info(\"Web application started.\")\n",
        "\n",
        "    # Simulate a successful request\n",
        "    app_logger.info(\"Simulating a successful request.\")\n",
        "    handle_request({'path': '/dashboard', 'user_id': '123'})\n",
        "\n",
        "    # Simulate a login attempt with sensitive data (handled safely by `handle_request`)\n",
        "    app_logger.info(\"Simulating a login attempt with sensitive data.\")\n",
        "    handle_request({'path': '/login', 'email': 'user@example.com', 'password': 'mySecretPassword123'})\n",
        "\n",
        "    # Simulate an error\n",
        "    app_logger.info(\"Simulating an error scenario.\")\n",
        "    handle_request({'path': '/api/data', 'user_id': '123', 'error_code': 500, 'error_message': 'Database connection failed'})\n",
        "\n",
        "    # Simulate another request without email\n",
        "    app_logger.info(\"Simulating another request without email.\")\n",
        "    handle_request({'path': '/profile', 'user_id': '456'})\n",
        "\n",
        "    app_logger.info(\"Web application shut down.\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,048 - web_app - INFO - Web application started.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Web application started.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,051 - web_app - INFO - Simulating a successful request.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Simulating a successful request.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,054 - web_app - INFO - Request received for path: /dashboard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request received for path: /dashboard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,057 - web_app - INFO - Login attempt detected (email not provided).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Login attempt detected (email not provided).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,060 - web_app - INFO - Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,064 - web_app - INFO - Simulating a login attempt with sensitive data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Simulating a login attempt with sensitive data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,067 - web_app - INFO - Request received for path: /login\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request received for path: /login\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,069 - web_app - INFO - Login attempt detected for user: us***@example.com\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Login attempt detected for user: us***@example.com\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,072 - web_app - INFO - Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,077 - web_app - INFO - Simulating an error scenario.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Simulating an error scenario.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,079 - web_app - INFO - Request received for path: /api/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request received for path: /api/data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,081 - web_app - INFO - Login attempt detected (email not provided).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Login attempt detected (email not provided).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,084 - web_app - ERROR - Application error: 500 - Database connection failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:web_app:Application error: 500 - Database connection failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,087 - web_app - WARNING - Investigate application error immediately.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:web_app:Investigate application error immediately.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,090 - web_app - INFO - Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,091 - web_app - INFO - Simulating another request without email.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Simulating another request without email.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,094 - web_app - INFO - Request received for path: /profile\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request received for path: /profile\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,095 - web_app - INFO - Login attempt detected (email not provided).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Login attempt detected (email not provided).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,097 - web_app - INFO - Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Request processing complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-29 08:23:27,099 - web_app - INFO - Web application shut down.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:web_app:Web application shut down.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lN9gfBJY3YaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "241133fd",
        "outputId": "1bbc0f60-ea03-4dac-ca8d-d940da09cd41"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Suppress warnings related to convergence\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Data Loading ---\n",
        "# The Iris dataset is a classic and simple dataset for classification.\n",
        "# It contains measurements of iris flowers and their species.\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = iris.target # Target (species: setosa, versicolor, virginica)\n",
        "\n",
        "print(\"Dataset loaded: Iris\")\n",
        "print(f\"Number of samples: {len(X)}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of classes: {len(iris.target_names)}\")\n",
        "print(f\"Feature names: {iris.feature_names}\")\n",
        "print(f\"Target names (species): {iris.target_names}\\n\")\n",
        "\n",
        "# --- 2. Data Splitting ---\n",
        "# Split the dataset into training and testing sets.\n",
        "# The training set is used to train the model, and the test set is used to evaluate its performance.\n",
        "# A common split is 70-80% for training and 20-30% for testing.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} samples\")\n",
        "print(f\"Test set size: {len(X_test)} samples\\n\")\n",
        "\n",
        "# --- 3. Model Training ---\n",
        "# We'll use Logistic Regression, a simple yet effective algorithm for binary and multi-class classification.\n",
        "# It's a linear model that calculates the probability of a sample belonging to a certain class.\n",
        "model = LogisticRegression(max_iter=200) # Increased max_iter to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Logistic Regression model trained.\\n\")\n",
        "\n",
        "# --- 4. Prediction ---\n",
        "# Make predictions on the unseen test data.\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Model predictions on test data:\")\n",
        "print(f\"Actual species (first 5):   {y_test[:5]}\")\n",
        "print(f\"Predicted species (first 5): {y_pred[:5]}\\n\")\n",
        "\n",
        "# --- 5. Model Evaluation ---\n",
        "# Evaluate the model's accuracy, which is the proportion of correctly predicted instances.\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on the test set: {accuracy:.2f}\\n\")\n",
        "\n",
        "\n",
        "# --- Responsible AI Documentation ---\n",
        "\n",
        "# 1. How the model makes decisions (Basic Explainability):\n",
        "#    - This Logistic Regression model learns a linear relationship between the input features\n",
        "#      (sepal length/width, petal length/width) and the probability of each flower species.\n",
        "#      It essentially draws decision boundaries in the feature space. For each flower, it calculates\n",
        "#      scores for each species and predicts the species with the highest score.\n",
        "#    - The 'coefficients' of the model (model.coef_ and model.intercept_) indicate how much\n",
        "#      each feature contributes to the prediction of each class. Positive coefficients mean\n",
        "#      that feature increases the likelihood of that class, negative means it decreases it.\n",
        "#      For example, a larger petal length might increase the likelihood of one species over another.\n",
        "\n",
        "# 2. Accuracy Limitations:\n",
        "#    - While this model achieves good accuracy on the Iris dataset, it's a very simple dataset.\n",
        "#      Real-world data is often more complex, noisy, and ambiguous.\n",
        "#    - Accuracy alone is not always sufficient. For multi-class problems, metrics like precision,\n",
        "#      recall, and F1-score (per class and macro/micro averages) provide a more nuanced view of performance.\n",
        "#    - The model's performance might degrade significantly on new, unseen data that differs from the training data.\n",
        "\n",
        "# 3. Warning against High-Risk Decisions:\n",
        "#    - This model, or any simple machine learning model, should NOT be used for high-stakes or\n",
        "#      critical decisions (e.g., medical diagnosis, financial lending, legal judgments) without extensive\n",
        "#      further validation, domain expertise, and human oversight.\n",
        "#    - Predictions are statistical probabilities, not absolute truths. A human expert should always\n",
        "#      review and take responsibility for decisions made based on model outputs in sensitive contexts.\n",
        "\n",
        "# 4. Possible Data Bias and its Impact:\n",
        "#    - Even simple datasets can have biases. For example, if the Iris dataset disproportionately\n",
        "#      represented certain species or was collected only from a specific region, the model might\n",
        "#      not generalize well to other species or regions.\n",
        "#    - If the training data contains imbalanced classes (e.g., very few samples of one species),\n",
        "#      the model might perform poorly on that underrepresented class.\n",
        "#    - Bias in data can lead to unfair or inaccurate predictions for certain groups or categories,\n",
        "#      even if the overall accuracy seems high.\n",
        "\n",
        "# 5. Responsible Usage and Regular Evaluation:\n",
        "#    - **Use Case Appropriateness**: Ensure the problem you're solving is suitable for ML and this model type.\n",
        "#    - **Continuous Monitoring**: Models degrade over time. Regularly monitor the model's performance\n",
        "#      in production with real-world data and retrain it as necessary.\n",
        "#    - **Fairness Audits**: Periodically check for unfair biases in predictions across different\n",
        "#      subgroups of data (e.g., different types of flowers, if applicable).\n",
        "#    - **Transparency**: Clearly communicate the model's purpose, capabilities, and limitations\n",
        "#      to users and stakeholders.\n",
        "#    - **Human-in-the-Loop**: Integrate human oversight, especially for predictions with low confidence\n",
        "#      or in critical applications, allowing humans to make final decisions."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: Iris\n",
            "Number of samples: 150\n",
            "Number of features: 4\n",
            "Number of classes: 3\n",
            "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Target names (species): ['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "Training set size: 105 samples\n",
            "Test set size: 45 samples\n",
            "\n",
            "Logistic Regression model trained.\n",
            "\n",
            "Model predictions on test data:\n",
            "Actual species (first 5):   [1 0 2 1 1]\n",
            "Predicted species (first 5): [1 0 2 1 1]\n",
            "\n",
            "Model Accuracy on the test set: 1.00\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1aySGWX3-ie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}